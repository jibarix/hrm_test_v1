# Complete laptop-optimized config for Simple Pathfinding
# Hardware: RTX 3070 Ti Laptop (8GB VRAM)  
# Dataset: 1000 examples, 6-token system
# WITH SPATIAL CONNECTIVITY FIX

defaults:
  - _self_

hydra:
  output_subdir: null

# Data path (updated for simplified pathfinding)
data_path: data/simple-pathfinding-1k

# Architecture
arch:
  name: hrm.hrm_act_v1@HierarchicalReasoningModel_ACTV1
  
  # Loss configuration WITH SPATIAL FIX
  loss:
    name: losses@ACTLossHead
    loss_type: stablemax_cross_entropy
    
    # SPATIAL CONNECTIVITY FIX - Core parameters
    enable_spatial_loss: true          # Enable the fundamental spatial fix
    spatial_penalty_weight: 10.0       # Penalty strength for impossible spatial jumps
    enable_connectivity_loss: false    # Start simple - disable additional connectivity check
    connectivity_weight: 5.0           # (unused when connectivity disabled)
    
    # Grid and token configuration (simplified 6-token system)
    grid_width: 40                     # 40Ã—40 grid dimensions
    path_token_id: 6                   # PATH token in simplified system

  # ACT (Adaptive Computation Time) settings
  halt_exploration_prob: 0.1           # Standard exploration probability
  halt_max_steps: 16                   # Max reasoning steps

  # Hierarchical reasoning cycles
  H_cycles: 2                          # High-level planning cycles
  L_cycles: 4                          # Low-level execution cycles

  # Transformer architecture (laptop-optimized)
  H_layers: 4                          # High-level module layers
  L_layers: 4                          # Low-level module layers
  hidden_size: 256                     # Model dimension (reduced for 8GB VRAM)
  num_heads: 4                         # Attention heads (reduced for efficiency)
  expansion: 4                         # FFN expansion ratio

  # Embeddings
  puzzle_emb_ndim: 256                 # Same as hidden_size

  # Position encodings
  pos_encodings: rope                  # Rotary position embeddings
  rms_norm_eps: 1e-5                   # RMSNorm epsilon
  rope_theta: 10000.0                  # RoPE base frequency

  # Forward pass dtype
  forward_dtype: bfloat16              # Mixed precision training

# Training hyperparameters (laptop-optimized)
global_batch_size: 32                 # Conservative for 8GB VRAM
epochs: 2000                          # Suitable for 1K dataset
eval_interval: 100                    # Frequent evaluation for debugging
checkpoint_every_eval: true           # Save checkpoints at each eval

# Learning rates
lr: 1e-4                              # Main learning rate
lr_min_ratio: 0.1                     # LR decay to 10% of original
lr_warmup_steps: 200                  # Short warmup for small dataset

# Optimizer settings (Adam-like, as in paper)
beta1: 0.9                            # Adam beta1
beta2: 0.95                           # Adam beta2 (slightly higher than default)

# Regularization
weight_decay: 1.0                     # Strong regularization for small dataset
puzzle_emb_weight_decay: 1.0          # Strong puzzle embedding regularization

# Puzzle embedding learning rate
puzzle_emb_lr: 1e-4                   # Same as main LR for simplicity

# Project and run naming (updated for simplified pathfinding)
project_name: null                    # Auto-generate: "Simple-pathfinding-1k ACT-torch"
run_name: null                        # Auto-generate: "HierarchicalReasoningModel_ACTV1 adjective-animal"
checkpoint_path: null                 # Auto-generate based on project/run names

# Experiment settings
seed: 0                               # Reproducibility
eval_save_outputs: ["inputs", "labels", "logits", "puzzle_identifiers"]  # Save for analysis

# ========================================================================
# SPATIAL FIX VALIDATION NOTES
# ========================================================================
# Key metrics to monitor for spatial fix validation:
#
# SUCCESS INDICATORS:
# - train/spatial_loss: Should decrease over time (model learning 2D constraints)
# - train/exact_accuracy: Should increase without path_ratio=1.0 cheating  
# - train/path_ratio: Should stay reasonable (<0.3), not spam entire grid
# - train/steps: Should show reasonable ACT step usage
#
# FAILURE INDICATORS:  
# - train/spatial_loss: Stays high (model not learning spatial constraints)
# - train/exact_accuracy: Stays at 0% (fundamental learning failure)
# - train/path_ratio: Goes to 1.0 (reverting to cheating behavior)
# - Loss explosion or training instability
#
# DEBUGGING:
# - If spatial_loss is too high, reduce spatial_penalty_weight to 5.0
# - If model still cheats, increase spatial_penalty_weight to 20.0
# - If training is unstable, reduce lr to 5e-5
# - Enable connectivity_loss if spatial fix alone isn't sufficient
#
# Expected training progression with spatial fix:
# - Steps 0-500: High spatial_loss as model learns constraints
# - Steps 500-1000: Spatial_loss decreases, accuracy starts improving
# - Steps 1000-1500: Breakthrough - exact_accuracy jumps to >10%
# - Steps 1500+: Continued improvement with stable spatial behavior
# ========================================================================