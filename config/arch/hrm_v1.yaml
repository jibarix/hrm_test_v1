name: hrm.hrm_act_v1@HierarchicalReasoningModel_ACTV1
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

halt_exploration_prob: 0.05    # REDUCED: Less random early halting (was 0.1)
halt_max_steps: 8              # INCREASED: Allow more computation (was 16, but effectively 0)

H_cycles: 2
L_cycles: 2

H_layers: 4
L_layers: 4

hidden_size: 256               # Reduced: Appropriate for our hardware (was 512)
num_heads: 8                   # min(2, hidden_size // 64)
expansion: 4

puzzle_emb_ndim: ${.hidden_size}

pos_encodings: rope

# MODIFICATIONS EXPLAINED:
# 1. halt_exploration_prob: 0.05 - Reduces random early halting
# 2. halt_max_steps: 8 - Reasonable computation budget
# 3. These should allow train/steps > 0 (actual thinking)